{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b6fcf3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# BO import\n",
    "from bayes_opt import BayesianOptimization\n",
    "from bayes_opt.util import acq_max\n",
    "from bayes_opt import UtilityFunction\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "\n",
    "# Kendall distance import\n",
    "from scipy.stats._stats import _kendall_dis\n",
    "\n",
    "# Kernel imports\n",
    "from sklearn.gaussian_process.kernels import StationaryKernelMixin, NormalizedKernelMixin, Kernel, Hyperparameter, _check_length_scale, _approx_fprime\n",
    "\n",
    "# Distance imports\n",
    "from scipy.spatial.distance import squareform\n",
    "\n",
    "# Other imports\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "453a12ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports with the problem\n",
    "from scipy.spatial.distance import pdist, cdist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b312e4cf",
   "metadata": {},
   "source": [
    "# Some definitions necessary for the program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adfa3ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kendall_distance(x,y):\n",
    "    perm = np.argsort(y)  # sort on y and convert y to dense ranks\n",
    "    x, y = x[perm], y[perm]\n",
    "    y = np.r_[True, y[1:] != y[:-1]].cumsum(dtype=np.intp)\n",
    "\n",
    "    # stable sort on x and convert x to dense ranks\n",
    "    perm = np.argsort(x, kind='mergesort')\n",
    "    x, y = x[perm], y[perm]\n",
    "    x = np.r_[True, x[1:] != x[:-1]].cumsum(dtype=np.intp)\n",
    "\n",
    "    dis = _kendall_dis(x, y)  # discordant pairs\n",
    "    return dis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b2b3ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_key(v):\n",
    "    permutation = np.argsort(v)\n",
    "    return permutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e05a43be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def black_box_function(**kwargs):\n",
    "    data = np.fromiter(kwargs.values(), dtype=float)\n",
    "    return np.sum(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86b74f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_bounds(n, lower_bound=0, upper_bound=1):\n",
    "    i = 0\n",
    "    pbounds = {}\n",
    "    while i < n:\n",
    "        xi = 'x' + str(i)\n",
    "        pbounds[xi] = (lower_bound, upper_bound)\n",
    "        i += 1\n",
    "    return pbounds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af198f9",
   "metadata": {},
   "source": [
    "# Definition of kernel.\n",
    "### Here the problem appears"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a2dfd4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PermutationRBF(StationaryKernelMixin, NormalizedKernelMixin, Kernel):\n",
    "    def __init__(self, alpha=1.0, alpha_bounds=(1e-5, 1e5)):\n",
    "        self.alpha = alpha\n",
    "        self.alpha_bounds = alpha_bounds\n",
    "\n",
    "    @property\n",
    "    def anisotropic(self):\n",
    "        return np.iterable(self.alpha) and len(self.alpha) > 1\n",
    "\n",
    "    @property\n",
    "    def hyperparameter_length_scale(self):\n",
    "        if self.anisotropic:\n",
    "            return Hyperparameter(\"length_scale\", \"numeric\",\n",
    "                                  self.alpha_bounds,\n",
    "                                  len(self.alpha))\n",
    "        return Hyperparameter(\n",
    "            \"alpha\", \"numeric\", self.alpha_bounds)\n",
    "\n",
    "    def __call__(self, X, Y=None, eval_gradient=False):\n",
    "        X = np.atleast_2d(X)\n",
    "        alpha = _check_length_scale(X, self.alpha)\n",
    "        if Y is None:\n",
    "            dists = pdist(X / alpha, kendall_distance)\n",
    "            K = np.exp(-.5 * dists)\n",
    "            # convert from upper-triangular matrix to square matrix\n",
    "            K = squareform(K)\n",
    "            np.fill_diagonal(K, 1)\n",
    "        else:\n",
    "            if eval_gradient:\n",
    "                raise ValueError(\n",
    "                    \"Gradient can only be evaluated when Y is None.\")\n",
    "            dists = cdist(X / alpha, Y / alpha, kendall_distance)\n",
    "            K = np.exp(-.5 * dists)\n",
    "        if eval_gradient:\n",
    "            if self.hyperparameter_length_scale.fixed:\n",
    "                # Hyperparameter l kept fixed\n",
    "                return K, np.empty((X.shape[0], X.shape[0], 0))\n",
    "            elif not self.anisotropic or alpha.shape[0] == 1:\n",
    "                K_gradient = \\\n",
    "                    (K * squareform(dists))[:, :, np.newaxis]\n",
    "                return K, K_gradient\n",
    "            elif self.anisotropic:\n",
    "                # We need to recompute the pairwise dimension-wise distances\n",
    "                K_gradient = (X[:, np.newaxis, :] - X[np.newaxis, :, :]) ** 2 \\\n",
    "                    / (alpha ** 2)\n",
    "                K_gradient *= K[..., np.newaxis]\n",
    "                return K, K_gradient\n",
    "        else:\n",
    "            return K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "402919ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RBF(StationaryKernelMixin, NormalizedKernelMixin, Kernel):\n",
    "    def __init__(self, length_scale=1.0, length_scale_bounds=(1e-5, 1e5)):\n",
    "        self.length_scale = length_scale\n",
    "        self.length_scale_bounds = length_scale_bounds\n",
    "\n",
    "    @property\n",
    "    def anisotropic(self):\n",
    "        return np.iterable(self.length_scale) and len(self.length_scale) > 1\n",
    "\n",
    "    @property\n",
    "    def hyperparameter_length_scale(self):\n",
    "        if self.anisotropic:\n",
    "            return Hyperparameter(\"length_scale\", \"numeric\",\n",
    "                                  self.length_scale_bounds,\n",
    "                                  len(self.length_scale))\n",
    "        return Hyperparameter(\n",
    "            \"length_scale\", \"numeric\", self.length_scale_bounds)\n",
    "\n",
    "    def __call__(self, X, Y=None, eval_gradient=False):\n",
    "        X = np.atleast_2d(X)\n",
    "        length_scale = _check_length_scale(X, self.length_scale)\n",
    "        if Y is None:\n",
    "            dists = pdist(X / length_scale, metric='sqeuclidean')\n",
    "            K = np.exp(-.5 * dists)\n",
    "            # convert from upper-triangular matrix to square matrix\n",
    "            K = squareform(K)\n",
    "            np.fill_diagonal(K, 1)\n",
    "        else:\n",
    "            if eval_gradient:\n",
    "                raise ValueError(\n",
    "                    \"Gradient can only be evaluated when Y is None.\")\n",
    "            dists = cdist(X / length_scale, Y / length_scale,\n",
    "                          metric='sqeuclidean')\n",
    "            K = np.exp(-.5 * dists)\n",
    "\n",
    "        if eval_gradient:\n",
    "            if self.hyperparameter_length_scale.fixed:\n",
    "                # Hyperparameter l kept fixed\n",
    "                return K, np.empty((X.shape[0], X.shape[0], 0))\n",
    "            elif not self.anisotropic or length_scale.shape[0] == 1:\n",
    "                K_gradient = \\\n",
    "                    (K * squareform(dists))[:, :, np.newaxis]\n",
    "                return K, K_gradient\n",
    "            elif self.anisotropic:\n",
    "                # We need to recompute the pairwise dimension-wise distances\n",
    "                K_gradient = (X[:, np.newaxis, :] - X[np.newaxis, :, :]) ** 2 \\\n",
    "                    / (length_scale ** 2)\n",
    "                K_gradient *= K[..., np.newaxis]\n",
    "                return K, K_gradient\n",
    "        else:\n",
    "            return K\n",
    "\n",
    "    def __repr__(self):\n",
    "        if self.anisotropic:\n",
    "            return \"{0}(length_scale=[{1}])\".format(\n",
    "                self.__class__.__name__, \", \".join(map(\"{0:.3g}\".format,\n",
    "                                                   self.length_scale)))\n",
    "        else:  # isotropic\n",
    "            return \"{0}(length_scale={1:.3g})\".format(\n",
    "                self.__class__.__name__, np.ravel(self.length_scale)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ce5069",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "648d0098",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyBayesianOptimization(BayesianOptimization):\n",
    "    def suggest(self, utility_function):\n",
    "        \"\"\"Most promissing point to probe next\"\"\"\n",
    "        if len(self._space) == 0:\n",
    "            return self._space.array_to_params(self._space.random_sample())\n",
    "\n",
    "        # Sklearn's GP throws a large number of warnings at times, but\n",
    "        # we don't really need to see them here.\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            self._gp.fit(self._space.params, self._space.target)\n",
    "\n",
    "        # Finding argmax of the acquisition function.\n",
    "        suggestion = acq_max(\n",
    "            ac=utility_function.utility,\n",
    "            gp=self._gp,\n",
    "            y_max=self._space.target.max(),\n",
    "            bounds=self._space.bounds,\n",
    "            random_state=self._random_state,\n",
    "            n_warmup=10000,\n",
    "            n_iter=0 # This is the only change of the method\n",
    "        )\n",
    "\n",
    "        return self._space.array_to_params(suggestion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0e4bb4",
   "metadata": {},
   "source": [
    "# Program starts here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c062a785",
   "metadata": {},
   "source": [
    "### Using my custom kernel (slow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "886225a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 20\n",
    "seed = 0\n",
    "it = 5\n",
    "kappa = 2.5\n",
    "xi = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c337948d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration:  0\n",
      "time:  0.0008704662322998047\n",
      "iteration:  1\n",
      "time:  1.2141697406768799\n",
      "iteration:  2\n",
      "time:  2.3469510078430176\n",
      "iteration:  3\n",
      "time:  3.5015127658843994\n",
      "iteration:  4\n",
      "time:  4.695566892623901\n"
     ]
    }
   ],
   "source": [
    "# Bounds of each variable\n",
    "pbounds = generate_bounds(n)\n",
    "\n",
    "# Bayesian Optimizer\n",
    "optimizer = MyBayesianOptimization(\n",
    "    f=None,\n",
    "    pbounds=pbounds,\n",
    "    verbose=2,\n",
    "    random_state=seed,\n",
    ")\n",
    "\n",
    "# Set the Kernel\n",
    "optimizer.set_gp_params(kernel=PermutationRBF())\n",
    "\n",
    "# Set the Acquisition function\n",
    "utility = UtilityFunction(kind=\"ucb\", kappa=kappa, xi=xi)\n",
    "\n",
    "# Bayesian Optimization with Gaussian Process\n",
    "for i in range(it):\n",
    "    t_ini = time.time()\n",
    "    next_point = optimizer.suggest(utility)\n",
    "    t_end = time.time() - t_ini\n",
    "    print('iteration: ',i)\n",
    "    print('time: ', t_end)\n",
    "    target = black_box_function(**next_point)\n",
    "    optimizer.register(params=next_point, target=target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f565def",
   "metadata": {},
   "source": [
    "### Using RBF kernel (very fast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cbe628c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 20\n",
    "seed = 0\n",
    "it = 5\n",
    "kappa = 2.5\n",
    "xi = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0aa0f07a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration:  0\n",
      "time:  0.000415802001953125\n",
      "iteration:  1\n",
      "time:  0.020179033279418945\n",
      "iteration:  2\n",
      "time:  0.033345937728881836\n",
      "iteration:  3\n",
      "time:  0.033483028411865234\n",
      "iteration:  4\n",
      "time:  0.0286252498626709\n"
     ]
    }
   ],
   "source": [
    "# Bounds of each variable\n",
    "pbounds = generate_bounds(n)\n",
    "\n",
    "# Bayesian Optimizer\n",
    "optimizer = MyBayesianOptimization(\n",
    "    f=None,\n",
    "    pbounds=pbounds,\n",
    "    verbose=2,\n",
    "    random_state=seed,\n",
    ")\n",
    "\n",
    "# Set the Kernel\n",
    "optimizer.set_gp_params(kernel=RBF())\n",
    "\n",
    "# Set the Acquisition function\n",
    "utility = UtilityFunction(kind=\"ucb\", kappa=kappa, xi=xi)\n",
    "\n",
    "# Bayesian Optimization with Gaussian Process\n",
    "for i in range(it):\n",
    "    t_ini = time.time()\n",
    "    next_point = optimizer.suggest(utility)\n",
    "    t_end = time.time() - t_ini\n",
    "    print('iteration: ',i)\n",
    "    print('time: ', t_end)\n",
    "    target = black_box_function(**next_point)\n",
    "    optimizer.register(params=next_point, target=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f437bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bayesian_optimization",
   "language": "python",
   "name": "bayesian_optimization"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

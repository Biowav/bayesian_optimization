{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05ad576c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import jit, njit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1df81aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distance imports\n",
    "from functools import partial\n",
    "\n",
    "import numpy as np\n",
    "from scipy._lib._util import _asarray_validated\n",
    "from scipy.spatial import _distance_wrap\n",
    "from scipy.spatial.distance import _args_to_kwargs_xdist, _METRIC_ALIAS, _filter_deprecated_kwargs, _METRICS, \\\n",
    "    mahalanobis, wminkowski, minkowski, seuclidean, _validate_cdist_input, _select_weighted_metric, _C_WEIGHTED_METRICS, \\\n",
    "    _TEST_METRICS, squareform, _validate_pdist_input, jensenshannon, _convert_to_type\n",
    "\n",
    "_convert_to_double = partial(_convert_to_type, out_type=np.double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b6fcf3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# BO import\n",
    "from bayes_opt import BayesianOptimization\n",
    "from bayes_opt.util import acq_max\n",
    "from bayes_opt import UtilityFunction\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "\n",
    "# Kendall distance import\n",
    "from scipy.stats._stats import _kendall_dis\n",
    "\n",
    "# Kernel imports\n",
    "from sklearn.gaussian_process.kernels import StationaryKernelMixin, NormalizedKernelMixin, Kernel, Hyperparameter, _check_length_scale, _approx_fprime\n",
    "\n",
    "# Distance imports\n",
    "from scipy.spatial.distance import squareform\n",
    "\n",
    "# Other imports\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "453a12ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports with the problem\n",
    "from scipy.spatial.distance import pdist, cdist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b312e4cf",
   "metadata": {},
   "source": [
    "# Some definitions necessary for the program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "adfa3ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kendall_distance(x,y):\n",
    "    perm = np.argsort(y)  # sort on y and convert y to dense ranks\n",
    "    x, y = x[perm], y[perm]\n",
    "    y = np.r_[True, y[1:] != y[:-1]].cumsum(dtype=np.intp)\n",
    "\n",
    "    # stable sort on x and convert x to dense ranks\n",
    "    perm = np.argsort(x, kind='mergesort')\n",
    "    x, y = x[perm], y[perm]\n",
    "    x = np.r_[True, x[1:] != x[:-1]].cumsum(dtype=np.intp)\n",
    "\n",
    "    dis = _kendall_dis(x, y)  # discordant pairs\n",
    "    return dis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b2b3ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_key(v):\n",
    "    permutation = np.argsort(v)\n",
    "    return permutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e05a43be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def black_box_function(**kwargs):\n",
    "    data = np.fromiter(kwargs.values(), dtype=float)\n",
    "    return np.sum(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86b74f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_bounds(n, lower_bound=0, upper_bound=1):\n",
    "    i = 0\n",
    "    pbounds = {}\n",
    "    while i < n:\n",
    "        xi = 'x' + str(i)\n",
    "        pbounds[xi] = (lower_bound, upper_bound)\n",
    "        i += 1\n",
    "    return pbounds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af198f9",
   "metadata": {},
   "source": [
    "# Definition of kernel.\n",
    "### Here the problem appears"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a2dfd4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PermutationRBF(StationaryKernelMixin, NormalizedKernelMixin, Kernel):\n",
    "    def __init__(self, alpha=1.0, alpha_bounds=(1e-5, 1e5)):\n",
    "        self.alpha = alpha\n",
    "        self.alpha_bounds = alpha_bounds\n",
    "\n",
    "    @property\n",
    "    def anisotropic(self):\n",
    "        return np.iterable(self.alpha) and len(self.alpha) > 1\n",
    "\n",
    "    @property\n",
    "    def hyperparameter_length_scale(self):\n",
    "        if self.anisotropic:\n",
    "            return Hyperparameter(\"length_scale\", \"numeric\",\n",
    "                                  self.alpha_bounds,\n",
    "                                  len(self.alpha))\n",
    "        return Hyperparameter(\n",
    "            \"alpha\", \"numeric\", self.alpha_bounds)\n",
    "\n",
    "    def __call__(self, X, Y=None, eval_gradient=False):\n",
    "        X = np.atleast_2d(X)\n",
    "        alpha = _check_length_scale(X, self.alpha)\n",
    "        if Y is None:\n",
    "            dists = custom_pdist(X / alpha, kendall_distance)\n",
    "            K = np.exp(-.5 * dists)\n",
    "            # convert from upper-triangular matrix to square matrix\n",
    "            K = squareform(K)\n",
    "            np.fill_diagonal(K, 1)\n",
    "        else:\n",
    "            if eval_gradient:\n",
    "                raise ValueError(\n",
    "                    \"Gradient can only be evaluated when Y is None.\")\n",
    "            dists = custom_cdist(X / alpha, Y / alpha, kendall_distance)\n",
    "            K = np.exp(-.5 * dists)\n",
    "        if eval_gradient:\n",
    "            if self.hyperparameter_length_scale.fixed:\n",
    "                # Hyperparameter l kept fixed\n",
    "                return K, np.empty((X.shape[0], X.shape[0], 0))\n",
    "            elif not self.anisotropic or alpha.shape[0] == 1:\n",
    "                K_gradient = \\\n",
    "                    (K * squareform(dists))[:, :, np.newaxis]\n",
    "                return K, K_gradient\n",
    "            elif self.anisotropic:\n",
    "                # We need to recompute the pairwise dimension-wise distances\n",
    "                K_gradient = (X[:, np.newaxis, :] - X[np.newaxis, :, :]) ** 2 \\\n",
    "                    / (alpha ** 2)\n",
    "                K_gradient *= K[..., np.newaxis]\n",
    "                return K, K_gradient\n",
    "        else:\n",
    "            return K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "402919ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RBF(StationaryKernelMixin, NormalizedKernelMixin, Kernel):\n",
    "    def __init__(self, length_scale=1.0, length_scale_bounds=(1e-5, 1e5)):\n",
    "        self.length_scale = length_scale\n",
    "        self.length_scale_bounds = length_scale_bounds\n",
    "\n",
    "    @property\n",
    "    def anisotropic(self):\n",
    "        return np.iterable(self.length_scale) and len(self.length_scale) > 1\n",
    "\n",
    "    @property\n",
    "    def hyperparameter_length_scale(self):\n",
    "        if self.anisotropic:\n",
    "            return Hyperparameter(\"length_scale\", \"numeric\",\n",
    "                                  self.length_scale_bounds,\n",
    "                                  len(self.length_scale))\n",
    "        return Hyperparameter(\n",
    "            \"length_scale\", \"numeric\", self.length_scale_bounds)\n",
    "\n",
    "    def __call__(self, X, Y=None, eval_gradient=False):\n",
    "        X = np.atleast_2d(X)\n",
    "        length_scale = _check_length_scale(X, self.length_scale)\n",
    "        if Y is None:\n",
    "            dists = pdist(X / length_scale, metric='sqeuclidean')\n",
    "            K = np.exp(-.5 * dists)\n",
    "            # convert from upper-triangular matrix to square matrix\n",
    "            K = squareform(K)\n",
    "            np.fill_diagonal(K, 1)\n",
    "        else:\n",
    "            if eval_gradient:\n",
    "                raise ValueError(\n",
    "                    \"Gradient can only be evaluated when Y is None.\")\n",
    "            dists = cdist(X / length_scale, Y / length_scale,\n",
    "                          metric='sqeuclidean')\n",
    "            K = np.exp(-.5 * dists)\n",
    "\n",
    "        if eval_gradient:\n",
    "            if self.hyperparameter_length_scale.fixed:\n",
    "                # Hyperparameter l kept fixed\n",
    "                return K, np.empty((X.shape[0], X.shape[0], 0))\n",
    "            elif not self.anisotropic or length_scale.shape[0] == 1:\n",
    "                K_gradient = \\\n",
    "                    (K * squareform(dists))[:, :, np.newaxis]\n",
    "                return K, K_gradient\n",
    "            elif self.anisotropic:\n",
    "                # We need to recompute the pairwise dimension-wise distances\n",
    "                K_gradient = (X[:, np.newaxis, :] - X[np.newaxis, :, :]) ** 2 \\\n",
    "                    / (length_scale ** 2)\n",
    "                K_gradient *= K[..., np.newaxis]\n",
    "                return K, K_gradient\n",
    "        else:\n",
    "            return K\n",
    "\n",
    "    def __repr__(self):\n",
    "        if self.anisotropic:\n",
    "            return \"{0}(length_scale=[{1}])\".format(\n",
    "                self.__class__.__name__, \", \".join(map(\"{0:.3g}\".format,\n",
    "                                                   self.length_scale)))\n",
    "        else:  # isotropic\n",
    "            return \"{0}(length_scale={1:.3g})\".format(\n",
    "                self.__class__.__name__, np.ravel(self.length_scale)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff75bff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_pdist(X, metric='euclidean', *args, **kwargs):\n",
    "    X = _asarray_validated(X, sparse_ok=False, objects_ok=True, mask_ok=True,\n",
    "                           check_finite=False)\n",
    "    kwargs = _args_to_kwargs_xdist(args, kwargs, metric, \"pdist\")\n",
    "\n",
    "    X = np.asarray(X, order='c')\n",
    "\n",
    "    s = X.shape\n",
    "    if len(s) != 2:\n",
    "        raise ValueError('A 2-dimensional array must be passed.')\n",
    "\n",
    "    m, n = s\n",
    "    out = kwargs.pop(\"out\", None)\n",
    "    if out is None:\n",
    "        dm = np.empty((m * (m - 1)) // 2, dtype=np.double)\n",
    "    else:\n",
    "        if out.shape != (m * (m - 1) // 2,):\n",
    "            raise ValueError(\"output array has incorrect shape.\")\n",
    "        if not out.flags.c_contiguous:\n",
    "            raise ValueError(\"Output array must be C-contiguous.\")\n",
    "        if out.dtype != np.double:\n",
    "            raise ValueError(\"Output array must be double type.\")\n",
    "        dm = out\n",
    "\n",
    "    # compute blocklist for deprecated kwargs\n",
    "    if(metric in _METRICS['jensenshannon'].aka\n",
    "       or metric == 'test_jensenshannon' or metric == jensenshannon):\n",
    "        kwargs_blocklist = [\"p\", \"w\", \"V\", \"VI\"]\n",
    "\n",
    "    elif(metric in _METRICS['minkowski'].aka\n",
    "         or metric in _METRICS['wminkowski'].aka\n",
    "         or metric in ['test_minkowski', 'test_wminkowski']\n",
    "         or metric in [minkowski, wminkowski]):\n",
    "        kwargs_blocklist = [\"V\", \"VI\"]\n",
    "\n",
    "    elif(metric in _METRICS['seuclidean'].aka or\n",
    "         metric == 'test_seuclidean' or metric == seuclidean):\n",
    "        kwargs_blocklist = [\"p\", \"w\", \"VI\"]\n",
    "\n",
    "    elif(metric in _METRICS['mahalanobis'].aka\n",
    "         or metric == 'test_mahalanobis' or metric == mahalanobis):\n",
    "        kwargs_blocklist = [\"p\", \"w\", \"V\"]\n",
    "\n",
    "    else:\n",
    "        kwargs_blocklist = [\"p\", \"V\", \"VI\"]\n",
    "\n",
    "    _filter_deprecated_kwargs(kwargs, kwargs_blocklist)\n",
    "\n",
    "    if callable(metric):\n",
    "        mstr = getattr(metric, '__name__', 'UnknownCustomMetric')\n",
    "        metric_name = _METRIC_ALIAS.get(mstr, None)\n",
    "\n",
    "        if metric_name is not None:\n",
    "            X, typ, kwargs = _validate_pdist_input(X, m, n,\n",
    "                                                   metric_name, **kwargs)\n",
    "\n",
    "        dm = calculate_pdist_dm(metric,dm,m,X,**kwargs)\n",
    "\n",
    "    elif isinstance(metric, str):\n",
    "        mstr = metric.lower()\n",
    "\n",
    "        mstr, kwargs = _select_weighted_metric(mstr, kwargs, out)\n",
    "\n",
    "        metric_name = _METRIC_ALIAS.get(mstr, None)\n",
    "\n",
    "        if metric_name is not None:\n",
    "            X, typ, kwargs = _validate_pdist_input(X, m, n,\n",
    "                                                   metric_name, **kwargs)\n",
    "\n",
    "            if 'w' in kwargs:\n",
    "                metric_name = _C_WEIGHTED_METRICS.get(metric_name, metric_name)\n",
    "\n",
    "            # get pdist wrapper\n",
    "            pdist_fn = getattr(_distance_wrap,\n",
    "                               \"pdist_%s_%s_wrap\" % (metric_name, typ))\n",
    "            pdist_fn(X, dm, **kwargs)\n",
    "            return dm\n",
    "\n",
    "        elif mstr in ['old_cosine', 'old_cos']:\n",
    "            warnings.warn('\"old_cosine\" is deprecated and will be removed in '\n",
    "                          'a future version. Use \"cosine\" instead.',\n",
    "                          DeprecationWarning)\n",
    "            X = _convert_to_double(X)\n",
    "            norms = np.einsum('ij,ij->i', X, X, dtype=np.double)\n",
    "            np.sqrt(norms, out=norms)\n",
    "            nV = norms.reshape(m, 1)\n",
    "            # The numerator u * v\n",
    "            nm = np.dot(X, X.T)\n",
    "            # The denom. ||u||*||v||\n",
    "            de = np.dot(nV, nV.T)\n",
    "            dm = 1.0 - (nm / de)\n",
    "            dm[range(0, m), range(0, m)] = 0.0\n",
    "            dm = squareform(dm)\n",
    "        elif mstr.startswith(\"test_\"):\n",
    "            if mstr in _TEST_METRICS:\n",
    "                dm = pdist(X, _TEST_METRICS[mstr], **kwargs)\n",
    "            else:\n",
    "                raise ValueError('Unknown \"Test\" Distance Metric: %s' % mstr[5:])\n",
    "        else:\n",
    "            raise ValueError('Unknown Distance Metric: %s' % mstr)\n",
    "    else:\n",
    "        raise TypeError('2nd argument metric must be a string identifier '\n",
    "                        'or a function.')\n",
    "    return dm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2e4bb872",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_cdist(XA, XB, metric='euclidean', *args, **kwargs):\n",
    "    kwargs = _args_to_kwargs_xdist(args, kwargs, metric, \"cdist\")\n",
    "\n",
    "    XA = np.asarray(XA, order='c')\n",
    "    XB = np.asarray(XB, order='c')\n",
    "\n",
    "    s = XA.shape\n",
    "    sB = XB.shape\n",
    "\n",
    "    if len(s) != 2:\n",
    "        raise ValueError('XA must be a 2-dimensional array.')\n",
    "    if len(sB) != 2:\n",
    "        raise ValueError('XB must be a 2-dimensional array.')\n",
    "    if s[1] != sB[1]:\n",
    "        raise ValueError('XA and XB must have the same number of columns '\n",
    "                         '(i.e. feature dimension.)')\n",
    "\n",
    "    mA = s[0]\n",
    "    mB = sB[0]\n",
    "    n = s[1]\n",
    "    out = kwargs.pop(\"out\", None)\n",
    "    if out is None:\n",
    "        dm = np.empty((mA, mB), dtype=np.double)\n",
    "    else:\n",
    "        if out.shape != (mA, mB):\n",
    "            raise ValueError(\"Output array has incorrect shape.\")\n",
    "        if not out.flags.c_contiguous:\n",
    "            raise ValueError(\"Output array must be C-contiguous.\")\n",
    "        if out.dtype != np.double:\n",
    "            raise ValueError(\"Output array must be double type.\")\n",
    "        dm = out\n",
    "\n",
    "    # compute blocklist for deprecated kwargs\n",
    "    if(metric in _METRICS['minkowski'].aka or\n",
    "       metric in _METRICS['wminkowski'].aka or\n",
    "       metric in ['test_minkowski', 'test_wminkowski'] or\n",
    "       metric in [minkowski, wminkowski]):\n",
    "        kwargs_blocklist = [\"V\", \"VI\"]\n",
    "    elif(metric in _METRICS['seuclidean'].aka or\n",
    "         metric == 'test_seuclidean' or metric == seuclidean):\n",
    "        kwargs_blocklist = [\"p\", \"w\", \"VI\"]\n",
    "    elif(metric in _METRICS['mahalanobis'].aka or\n",
    "         metric == 'test_mahalanobis' or metric == mahalanobis):\n",
    "        kwargs_blocklist = [\"p\", \"w\", \"V\"]\n",
    "    else:\n",
    "        kwargs_blocklist = [\"p\", \"V\", \"VI\"]\n",
    "\n",
    "    _filter_deprecated_kwargs(kwargs, kwargs_blocklist)\n",
    "\n",
    "    if callable(metric):\n",
    "\n",
    "        mstr = getattr(metric, '__name__', 'Unknown')\n",
    "        metric_name = _METRIC_ALIAS.get(mstr, None)\n",
    "\n",
    "        XA, XB, typ, kwargs = _validate_cdist_input(XA, XB, mA, mB, n,\n",
    "                                                    metric_name, **kwargs)\n",
    "\n",
    "        dm = calculate_cdist_dm(metric,dm,mA,mB,XA,XB,**kwargs)\n",
    "\n",
    "    elif isinstance(metric, str):\n",
    "        mstr = metric.lower()\n",
    "\n",
    "        mstr, kwargs = _select_weighted_metric(mstr, kwargs, out)\n",
    "\n",
    "        metric_name = _METRIC_ALIAS.get(mstr, None)\n",
    "        if metric_name is not None:\n",
    "            XA, XB, typ, kwargs = _validate_cdist_input(XA, XB, mA, mB, n,\n",
    "                                                        metric_name, **kwargs)\n",
    "\n",
    "            if 'w' in kwargs:\n",
    "                metric_name = _C_WEIGHTED_METRICS.get(metric_name, metric_name)\n",
    "\n",
    "            # get cdist wrapper\n",
    "            cdist_fn = getattr(_distance_wrap,\n",
    "                               \"cdist_%s_%s_wrap\" % (metric_name, typ))\n",
    "            cdist_fn(XA, XB, dm, **kwargs)\n",
    "            return dm\n",
    "\n",
    "        elif mstr.startswith(\"test_\"):\n",
    "            if mstr in _TEST_METRICS:\n",
    "                dm = cdist(XA, XB, _TEST_METRICS[mstr], **kwargs)\n",
    "            else:\n",
    "                raise ValueError('Unknown \"Test\" Distance Metric: %s' % mstr[5:])\n",
    "        else:\n",
    "            raise ValueError('Unknown Distance Metric: %s' % mstr)\n",
    "    else:\n",
    "        raise TypeError('2nd argument metric must be a string identifier '\n",
    "                        'or a function.')\n",
    "    return dm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "01ce5069",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def calculate_pdist_dm(metric,dm,m,X,**kwargs):\n",
    "    k = 0\n",
    "    for i in range(0, m - 1):\n",
    "        for j in range(i + 1, m):\n",
    "            dm[k] = metric(X[i], X[j], **kwargs)\n",
    "            k = k + 1\n",
    "    return dm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5cd2fbfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def calculate_cdist_dm(metric,dm,mA,mB,XA,XB,**kwargs):\n",
    "    for i in range(0, mA):\n",
    "        for j in range(0, mB):\n",
    "            dm[i, j] = metric(XA[i], XB[j], **kwargs)\n",
    "    return dm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "648d0098",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyBayesianOptimization(BayesianOptimization):\n",
    "    def suggest(self, utility_function):\n",
    "        \"\"\"Most promissing point to probe next\"\"\"\n",
    "        if len(self._space) == 0:\n",
    "            return self._space.array_to_params(self._space.random_sample())\n",
    "\n",
    "        # Sklearn's GP throws a large number of warnings at times, but\n",
    "        # we don't really need to see them here.\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            self._gp.fit(self._space.params, self._space.target)\n",
    "\n",
    "        # Finding argmax of the acquisition function.\n",
    "        suggestion = acq_max(\n",
    "            ac=utility_function.utility,\n",
    "            gp=self._gp,\n",
    "            y_max=self._space.target.max(),\n",
    "            bounds=self._space.bounds,\n",
    "            random_state=self._random_state,\n",
    "            n_warmup=10000,\n",
    "            n_iter=0 # This is the only change of the method\n",
    "        )\n",
    "\n",
    "        return self._space.array_to_params(suggestion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc243bf7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ac0e4bb4",
   "metadata": {},
   "source": [
    "# Program starts here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c062a785",
   "metadata": {},
   "source": [
    "### Using my custom kernel (slow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "886225a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 20\n",
    "seed = 0\n",
    "it = 5\n",
    "kappa = 2.5\n",
    "xi = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c337948d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration:  0\n",
      "time:  0.00023889541625976562\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "not enough arguments: expected 5, got 4",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-0e140c2e227c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mt_ini\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mnext_point\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuggest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mutility\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0mt_end\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt_ini\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'iteration: '\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-1069257a7221>\u001b[0m in \u001b[0;36msuggest\u001b[0;34m(self, utility_function)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_warnings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m# Finding argmax of the acquisition function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bayesian_optimization/lib/python3.9/site-packages/sklearn/gaussian_process/_gpr.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m             \u001b[0;31m# First optimize starting from theta specified in kernel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m             optima = [(self._constrained_optimization(obj_func,\n\u001b[0m\u001b[1;32m    239\u001b[0m                                                       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m                                                       self.kernel_.bounds))]\n",
      "\u001b[0;32m~/anaconda3/envs/bayesian_optimization/lib/python3.9/site-packages/sklearn/gaussian_process/_gpr.py\u001b[0m in \u001b[0;36m_constrained_optimization\u001b[0;34m(self, obj_func, initial_theta, bounds)\u001b[0m\n\u001b[1;32m    501\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_constrained_optimization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_theta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbounds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"fmin_l_bfgs_b\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 503\u001b[0;31m             opt_res = scipy.optimize.minimize(\n\u001b[0m\u001b[1;32m    504\u001b[0m                 \u001b[0mobj_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_theta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"L-BFGS-B\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjac\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m                 bounds=bounds)\n",
      "\u001b[0;32m~/anaconda3/envs/bayesian_optimization/lib/python3.9/site-packages/scipy/optimize/_minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    617\u001b[0m                                   **options)\n\u001b[1;32m    618\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'l-bfgs-b'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 619\u001b[0;31m         return _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[0m\u001b[1;32m    620\u001b[0m                                 callback=callback, **options)\n\u001b[1;32m    621\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'tnc'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bayesian_optimization/lib/python3.9/site-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0miprint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdisp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m     sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n\u001b[0m\u001b[1;32m    307\u001b[0m                                   \u001b[0mbounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_bounds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m                                   finite_diff_rel_step=finite_diff_rel_step)\n",
      "\u001b[0;32m~/anaconda3/envs/bayesian_optimization/lib/python3.9/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36m_prepare_scalar_function\u001b[0;34m(fun, x0, jac, args, bounds, epsilon, finite_diff_rel_step, hess)\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;31m# ScalarFunction caches. Reuse of fun(x) during grad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m     \u001b[0;31m# calculation reduces overall function evaluations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m     sf = ScalarFunction(fun, x0, args, grad, hess,\n\u001b[0m\u001b[1;32m    262\u001b[0m                         finite_diff_rel_step, bounds, epsilon=epsilon)\n\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bayesian_optimization/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fun, x0, args, grad, hess, finite_diff_rel_step, finite_diff_bounds, epsilon)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_fun_impl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;31m# Gradient evaluation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bayesian_optimization/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36m_update_fun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    224\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_update_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_updated\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_fun_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_updated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bayesian_optimization/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36mupdate_fun\u001b[0;34m()\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun_wrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_fun_impl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bayesian_optimization/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36mfun_wrapped\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mfun_wrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnfev\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bayesian_optimization/lib/python3.9/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;34m\"\"\" returns the the function value \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_if_needed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bayesian_optimization/lib/python3.9/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36m_compute_if_needed\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjac\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m             \u001b[0mfg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjac\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bayesian_optimization/lib/python3.9/site-packages/sklearn/gaussian_process/_gpr.py\u001b[0m in \u001b[0;36mobj_func\u001b[0;34m(theta, eval_gradient)\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mobj_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_gradient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0meval_gradient\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m                     lml, grad = self.log_marginal_likelihood(\n\u001b[0m\u001b[1;32m    231\u001b[0m                         theta, eval_gradient=True, clone_kernel=False)\n\u001b[1;32m    232\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mlml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bayesian_optimization/lib/python3.9/site-packages/sklearn/gaussian_process/_gpr.py\u001b[0m in \u001b[0;36mlog_marginal_likelihood\u001b[0;34m(self, theta, eval_gradient, clone_kernel)\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0meval_gradient\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m             \u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK_gradient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_train_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_gradient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m             \u001b[0mK\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_train_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-d8db041ed9c8>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, X, Y, eval_gradient)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_length_scale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mY\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0mdists\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcustom_pdist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkendall_distance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m             \u001b[0mK\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdists\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;31m# convert from upper-triangular matrix to square matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-c488adda1ec8>\u001b[0m in \u001b[0;36mcustom_pdist\u001b[0;34m(X, metric, *args, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m                                                    metric_name, **kwargs)\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0mdm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_pdist_dm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: not enough arguments: expected 5, got 4"
     ]
    }
   ],
   "source": [
    "# Bounds of each variable\n",
    "pbounds = generate_bounds(n)\n",
    "\n",
    "# Bayesian Optimizer\n",
    "optimizer = MyBayesianOptimization(\n",
    "    f=None,\n",
    "    pbounds=pbounds,\n",
    "    verbose=2,\n",
    "    random_state=seed,\n",
    ")\n",
    "\n",
    "# Set the Kernel\n",
    "optimizer.set_gp_params(kernel=PermutationRBF())\n",
    "\n",
    "# Set the Acquisition function\n",
    "utility = UtilityFunction(kind=\"ucb\", kappa=kappa, xi=xi)\n",
    "\n",
    "# Bayesian Optimization with Gaussian Process\n",
    "for i in range(it):\n",
    "    t_ini = time.time()\n",
    "    next_point = optimizer.suggest(utility)\n",
    "    t_end = time.time() - t_ini\n",
    "    print('iteration: ',i)\n",
    "    print('time: ', t_end)\n",
    "    target = black_box_function(**next_point)\n",
    "    optimizer.register(params=next_point, target=target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f565def",
   "metadata": {},
   "source": [
    "### Using RBF kernel (very fast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cbe628c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 20\n",
    "seed = 0\n",
    "it = 5\n",
    "kappa = 2.5\n",
    "xi = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0aa0f07a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration:  0\n",
      "time:  0.0004973411560058594\n",
      "iteration:  1\n",
      "time:  0.03358173370361328\n",
      "iteration:  2\n",
      "time:  0.01837444305419922\n",
      "iteration:  3\n",
      "time:  0.017252445220947266\n",
      "iteration:  4\n",
      "time:  0.010966300964355469\n"
     ]
    }
   ],
   "source": [
    "# Bounds of each variable\n",
    "pbounds = generate_bounds(n)\n",
    "\n",
    "# Bayesian Optimizer\n",
    "optimizer = MyBayesianOptimization(\n",
    "    f=None,\n",
    "    pbounds=pbounds,\n",
    "    verbose=2,\n",
    "    random_state=seed,\n",
    ")\n",
    "\n",
    "# Set the Kernel\n",
    "optimizer.set_gp_params(kernel=RBF())\n",
    "\n",
    "# Set the Acquisition function\n",
    "utility = UtilityFunction(kind=\"ucb\", kappa=kappa, xi=xi)\n",
    "\n",
    "# Bayesian Optimization with Gaussian Process\n",
    "for i in range(it):\n",
    "    t_ini = time.time()\n",
    "    next_point = optimizer.suggest(utility)\n",
    "    t_end = time.time() - t_ini\n",
    "    print('iteration: ',i)\n",
    "    print('time: ', t_end)\n",
    "    target = black_box_function(**next_point)\n",
    "    optimizer.register(params=next_point, target=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f437bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0441a898",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41f48b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3f3991a7",
   "metadata": {},
   "source": [
    "# Numba test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4fe23898",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_numba():\n",
    "    k = 0\n",
    "    for i in range(10000):\n",
    "        for j in range(10000):\n",
    "            k += 1\n",
    "    return k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0d0e49b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.9768311977386475"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_ini = time.time()\n",
    "test_numba()\n",
    "t_end = time.time() - t_ini\n",
    "t_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dba0b120",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def test_numba_jit():\n",
    "    k = 0\n",
    "    for i in range(10000):\n",
    "        for j in range(10000):\n",
    "            k += 1\n",
    "    return k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dd0d07cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12893915176391602"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_ini = time.time()\n",
    "test_numba_jit()\n",
    "t_end = time.time() - t_ini\n",
    "t_end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bayesian_optimization",
   "language": "python",
   "name": "bayesian_optimization"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
